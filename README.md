# optimizer-visualization
Visualize loss minimization techniques in Tensorflow.

![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/movie.gif)

#### AdadeltaOptimizer(learning_rate=50):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/AdadeltaOp_2.png)

#### AdagradOptimizer(learning_rate=0.05):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/AdagradOp_2.png)

#### AdamOptimizer(learning_rate=0.05):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/AdamOp_2.png)

#### FtrlOptimizer(learning_rate=0.05):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/FtrlOp_2.png)

#### GradientDescentOptimizer(learning_rate=0.05):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/GDOp_2.png)

#### MomentumOptimizer(learning_rate=0.05, momentum=0.9)
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/MomentumOp_2.png)

#### RMSPropOptimizer(learning_rate=0.05)
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/RMSPropOp_2.png)



#### AdadeltaOptimizer(learning_rate=1000):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/AdadeltaOp.png)

#### AdagradOptimizer(learning_rate=0.5):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/AdagradOp.png)

#### AdamOptimizer(learning_rate=0.5):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/AdamOp.png)

#### FtrlOptimizer(learning_rate=0.5):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/FtrlOp.png)

#### GradientDescentOptimizer(learning_rate=0.05):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/GDOp.png)

#### MomentumOptimizer(learning_rate=0.05, momentum=0.9)
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/MomentumOp.png)

#### ProximalAdagradOptimizer(learning_rate=0.5):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/ProximalAdagradOp.png)

#### ProximalGradientDescentOptimizer(learning_rate=0.05):
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/ProximalGDOp.png)

#### RMSPropOptimizer(learning_rate=0.5)
![](https://github.com/Jaewan-Yun/optimizer-visualization/blob/master/visuals/RMSPropOp.png)

#### Inspired by the following GIFs I found on the web:

![](https://i.stack.imgur.com/qAx2i.gif)
![](https://i.stack.imgur.com/1obtV.gif)